# 大文件上传

## 整体思路

### 前端
    前端大文件上传网上的大部分文章已经给出了解决方案 , 核心是 利用 Blob.prototype.slice 方法 , 调用 slice 方法可以返回 原文件的某个切片

    这样我们就可以根据预先设置好的切片最大数量将文件切分为一个个切片 , 然后借助 http 的可并发性 , 同时上传多个切片 , 这样从原本传一个大文件 , 变成了 同时传 多个小的文件切片 , 可以大大减少上传时间

    另外由于是并发 , 传输到服务端的顺序可能会发生变化 , 所以我们还需要给每个切片记录顺序

### 服务端
    服务端需要负责接受这些切片 , 并在接收到所有切片后 合并切片

    这里有两个问题
    1. 何时合并切片 , 即切片什么时间传输完成
    2. 如何合并切片

    第一个问题需要前端进行配合 , 前端在每个切片中都携带切片最大数量的信息 , 当服务端接收到这个数量的切片时自动合并 , 也可以额外发送一个请求主动通知服务端进行切片的合并

    第二个问题 , 具体如何合并切片呢 ? 这里可以使用 node.js 的读写流 (readStream / writeStream) , 将所有切片的流传输到最终文件流里
